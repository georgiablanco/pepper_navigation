# pepper_navigation
Restaurant navigation using the Pepper Robot

This repo shows code from my disseration HRI and Navigation in hospitality.
Report can be found here: https://www.researchgate.net/publication/341508891_Human-Robot_Interaction_and_Navigation_in_Hospitality

This is a demonstration of how safe and efficient navigation was achieved using SoftBanks Pepper robot; 2D and 3D SLAM were used in combination with 2D path planning to produce a 2.5D navigation
pipeline. This was completed inside the Robot Operating System (ROS) framework.  
  
# 3D octomap
![alt text](https://github.com/georgiablanco/pepper_navigation/blob/master/octo3D.png)  

# RTABMAP SIFT Descriptors
![alt text](https://github.com/georgiablanco/pepper_navigation/blob/master/rtabmap_view1.png)  

# Explaination
Navigation in hospitality is explored using consideration of environmental variables in the third dimension. It
was determined that this consideration is crucial for safe and efficient navigation for a humanoid robot of
Pepper’s size by exploring path planning in series of restaurant environments with open and cluttered areas,
such as tables of varying size and height, chairs, sofas, people and doorways where Pepper can and cannot fit.
2D occupancy maps were generated by SLAM Gmapping and Ocotmap in parallel and the chosen path
planning algorithms were deployed on Pepper and evaluated for accuracy, efficiency and speed.
While paths planned in SLAM Gmapping can be successful, Pepper sometimes became stuck or would have
to re-plan when planning routes through obstacles that are not detected by Pepper’s laser as the obstacles were
not ground-based. This was overcome by Octomap producing a 2D down-projected map from a 3D occupancy
grid with maximum z-axis recording of 1.4m which is just above Pepper’s height. The maps produced enabled
the 2D navigation stack to successfully plan routes in all restaurants without remapping as the global map
accounted for obstacles in the third dimension. By using a 3D map projection alongside a 2D path planner a
2.5D navigation pipeline is generated. This pipeline ensures computational efficiency whilst retaining the
environment information needed for safe path planning.
From this, it was deduced that, alongside Dijkstra’s global planner, TEB local planner outperformed the other
local planners in optimisation and speed. TEB also prevailed when obstacles were placed in real-time into the
simulation to test dynamic obstacle avoidance.
Furthermore, localisation in 2D was underperforming due to Pepper’s ground laser sensors being unable to
interpret and localise in the environment accurately. This produced undesirable results in some path planning
routes when Pepper became lost and unable to recover its current pose.
To mitigate the localisation problem and therefore producing a fully functional navigation pipeline, RTABMap was introduced. This algorithm produces accurate SLAM using Peppers RGB and Depth camera data.
Thus, Pepper was able to successfully perform localisation in both mapping and path planning stages with the
Dijkstra’s and TEB planner remaining the most successful global and local planner pair. As the simulation
reflects the sensor and odometry data Pepper would produce in real life, RTAB-Map employed with the 2D
navigation stack reflects a successful solution for humanoid robot navigation and autonomous path planning
on both simulated and real-world restaurant environments.

For future work, the use of RTAB-Map for path planning can be tested in the real world to confirm this
conclusion and the integration of sensors that produce higher quality data would benefit Pepper’s ability to
navigate
